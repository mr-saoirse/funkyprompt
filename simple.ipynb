{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1ff527b",
   "metadata": {},
   "source": [
    "# Step 1 - call a model (make sure to set your open ai key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc7813d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import openai\n",
    "\n",
    "DEFAULT_MODEL = \"gpt-4o-2024-08-06\"  # \"gpt-4-1106-preview\"\n",
    "GPT_MINI = \"gpt-4o-mini\"\n",
    "prompt = \"help the user out\"\n",
    "\n",
    "question = \"what is the best thing about the dutch\"\n",
    "messages = [\n",
    "     {\"role\": \"system\", \"content\": prompt},\n",
    "     {\"role\": \"user\", \"content\": question}\n",
    "]\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "        model=GPT_MINI,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        response_format=None, #can be json like,\n",
    "        stream=None\n",
    "    )\n",
    "    \n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2641e36e",
   "metadata": {},
   "source": [
    "# Step 2 - call a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a9b775",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "there are probably lots of ways to do this - i went first principles to show the idea \n",
    "and assume (brittle) a doc string so we dont need to much code for handling types etc\n",
    "\"\"\"\n",
    "\n",
    "def describe_function(fn):\n",
    "    \"\"\"this is a simplistic thing that generates openai schema for functions from doc strings\n",
    "       this is not what i do but its a way to do it fast and since what happens\n",
    "    \"\"\"\n",
    "    import docstring_parser\n",
    "    a=docstring_parser.parse(fn.__doc__)\n",
    "\n",
    "    return {\n",
    "        \"name\": fn.__name__, \n",
    "        \"description\": a.description,\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": { p.arg_name :{\"type\":p.type_name, \"description\": p.description}  for p in a.params }\n",
    "        }\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba9a23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"can you call my function please and pass hi as the param\"\n",
    "messages = [\n",
    "     {\"role\": \"system\", \"content\": prompt},\n",
    "     {\"role\": \"user\", \"content\": question}\n",
    "]\n",
    "\n",
    "def my_function(param: str):\n",
    "    \"\"\"\n",
    "    this function spits out a param\n",
    "    \n",
    "    Args:\n",
    "        param(string): the param \n",
    "    \"\"\"\n",
    "    \n",
    "    return f\"You said {param} and its nice to meet you\"\n",
    "\n",
    "\"\"\"\n",
    "if you were super strict with doc strings this would work\n",
    "\"\"\" \n",
    "functions = [describe_function(my_function)]\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "        model=GPT_MINI,\n",
    "        functions=functions,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        response_format=None, #can be json like,\n",
    "        stream=None\n",
    "    )\n",
    "\n",
    "fcall = response.choices[0].message.function_call\n",
    "fcall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17b9167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def invoker(call):\n",
    "    \"\"\"you can call using the openapi object\n",
    "       parse the json arguments with your checks etc\n",
    "       handle exceptions and all that jazz\n",
    "       generally try to return a json response\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"status\": \"you have called the function\",\n",
    "      f\"response from function {fcall.name}\" : eval(call.name)(**json.loads(call.arguments)) \n",
    "    } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c0d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoker(fcall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7f880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 understand the states in the loop and look for stoping conditions\n",
    "\n",
    "question = \"what was the result of calling the function with parameter Ireland\"\n",
    "messages = [\n",
    "     {\"role\": \"system\", \"content\": \"Use any functions you have to answer the users question\"},\n",
    "     {\"role\": \"user\", \"content\": question}\n",
    "]\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    \"\"\"fixed function list above, i usually dynmically add functions\"\"\"\n",
    "    response = openai.chat.completions.create(\n",
    "        model=GPT_MINI,\n",
    "        functions=functions,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        response_format=None, #can be json like,\n",
    "    )\n",
    "    fcall = response.choices[0].message.function_call\n",
    "    if fcall:\n",
    "        \"\"\"note the role is a funciton now\"\"\"\n",
    "        messages.append({\n",
    "            'role': 'function',\n",
    "            'name': fcall.name,\n",
    "            'content': json.dumps(invoker(fcall), default=str)\n",
    "        })\n",
    "        \"\"\"messages are now updated \"\"\"\n",
    "    else:\n",
    "        pass\n",
    "    if response.choices[0].finish_reason == 'stop':\n",
    "        break\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61699f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# uri = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet'\n",
    "#!wget https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet ~/Downloads\n",
    "file = f\"{Path.home()}/Downloads/yellow_tripdata_2024-01.parquet\"\n",
    "\n",
    "\n",
    "def get_query(question, file, extra_hints: str= None):\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    \"\"\"probe for schema and enums etc...\"\"\"\n",
    "    data = duckdb.execute(f\" select * from '{file}' limit 1\")\n",
    "    columns = dict(data.df().dtypes)\n",
    "    \n",
    "    prompt= f\"\"\"\n",
    "    Please provide an sql query using Duck DB dialect to answer the users question for a table called TABLE The schema for the data are\n",
    "    ```json\n",
    "    {columns}\n",
    "    ```\n",
    "    \n",
    "    You can response using this model in Json\n",
    "    \n",
    "    class MyModel(BaseModel):\n",
    "        sql: str\n",
    "        comment: str\n",
    "        \n",
    "    ### hints\n",
    "    ```\n",
    "    {extra_hints}\n",
    "    ```\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = [\n",
    "         {\"role\": \"system\", \"content\": prompt},\n",
    "         {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "            model=GPT_MINI,\n",
    "            messages=messages,\n",
    "            temperature=0,\n",
    "            response_format=  {\"type\": \"json_object\"}\n",
    "        )\n",
    "\n",
    "    data =  json.loads(response.choices[0].message.content)\n",
    "    data['sql'] = data['sql'].replace('TABLE', f\"'{file}'\")\n",
    "    print(data['sql'])\n",
    "    return data\n",
    "\n",
    "query = get_query('what were the total surcharges', file)\n",
    "\n",
    "duckdb.execute(query['sql']).df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b26516",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = get_query('please provide 10 sample rows', file)\n",
    "duckdb.execute(query['sql']).df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8335cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#breaks down\n",
    "query = get_query('what day had the largest congestion surcharge', file)\n",
    "duckdb.execute(query['sql']).df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d957d427",
   "metadata": {},
   "outputs": [],
   "source": [
    "hints = \"\"\"## Working with duckdb dialect\n",
    "\n",
    " ### 1 some example *list* column type functions\n",
    "    - Un-nesting list types: You can use the UNEST function as per the following example taking care of column names and alias if you want to perform aggregations on list types.\n",
    "\n",
    "```sql\n",
    "    -- use CTEs with group by to avoid aliasing confusion - this example unnests a list\n",
    "    WITH unnested_sku AS (\n",
    "            SELECT   UNNEST(skus) AS individual_sku  FROM  TABLE\n",
    "        )\n",
    "        SELECT    individual_sku,  COUNT(*) AS frequency  FROM  unnested_sku\n",
    "        GROUP BY   individual_sku\n",
    "        ORDER BY frequency\n",
    "```\n",
    "\n",
    "### 2 Here are some example *date functions* should you need them\n",
    "- truncate to precision using `date_trunc(part,date_column)` for example to get the date only  `date_trunc('day', date_column)`\n",
    "- we can get date differences and sample parts with - `date_diff(part, startdate, enddate)`\n",
    "- when asked date based questions be liberal with the dates e.g. treat \"this week\" as the last 7 days or this month as the last 4 weeks\n",
    "- do not use `date_sub` in duckdb queries - see example below for adding negative offsets\n",
    "- casting dates e.g. DATE '1992-03-22' (but you can assume dates are already in the correct type and not strings by default)\n",
    "- do not use the function `NOW()` use `current_date()` instead for the current date time\n",
    "\n",
    "#### Some other examples\n",
    "\n",
    "**Add or Subtract the interval to the date using `date_add(date, interval)`. Note we add negative numbers for subtraction**\n",
    "- For example,\t```date_add(DATE '1992-09-15', INTERVAL 2 MONTH)``` results in `1992-11-15`\n",
    "- Subtraction uses ` - INTERVAL` e.g.  \t```date_add(DATE '1992-09-15', - INTERVAL 3 MONTH``` results in `1992-06-15`\n",
    "\n",
    "**Getting the number of partition boundaries between the dates**\n",
    "-\t`date_diff('month', DATE '1992-09-15', DATE '1992-11-14')`\n",
    "\n",
    "**Get the subfield (equivalent to extract) of the date using `date_part(part,date)`**\n",
    "- \t`date_part('year', DATE '1992-09-20')` results in `1992`\"\"\"\n",
    "\n",
    "query = get_query('what day had the largest congestion surcharge', file, extra_hints=hints)\n",
    "duckdb.execute(query['sql']).df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad3cf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = get_query('what are all the payment types', file, extra_hints=hints)\n",
    "duckdb.execute(query['sql']).df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e4948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = get_query('what was the average distance travelled', file, extra_hints=hints)\n",
    "duckdb.execute(query['sql']).df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1181e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
