---
description: The best prompts are no prompts
---

# Why funkyprompt

The LLM and LLM tool space is noisy so we very thoughtfully introduce a new but very simple tool into this space. The goal is to focus on powerful predictability. This is done by respecting the interface between (a) the LLM such as OpenAI chat completions with functions interface and (b) everything else i.e. our code. `funkyprompt` works by exploring how we can write code as we always have done with typing and doc strings and avoid writing prompts at all.

At the core we run a single interpreter, which basically loops and tries to solve problems while calling out to supplied functions. But its a bit more exciting than that. This is a pattern that subsumes zero shot, conversational, planning and multi agent systems in a purely functional way.&#x20;

The library provides tools for understanding how the LLM inspects our functions and plans. It explores where the LLM does well and where it trips up.&#x20;

## Install

## CLI

## Serve

## Deploy to Coud

## Where next?

<table data-view="cards"><thead><tr><th></th><th></th><th></th></tr></thead><tbody><tr><td></td><td><a data-mention href="broken-reference">Broken link</a></td><td></td></tr><tr><td></td><td><a data-mention href="broken-reference">Broken link</a></td><td></td></tr><tr><td></td><td><a data-mention href="broken-reference">Broken link</a></td><td></td></tr></tbody></table>
